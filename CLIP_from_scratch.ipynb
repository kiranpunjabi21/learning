{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ly0GAJmWTuim",
        "outputId": "2738d2f2-d93c-4635-938f-e98e7c0ea469"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJ69LlZbnN7g",
        "outputId": "07ae2f5f-eba4-4671-a190-8d8ed0e4849c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.9.8-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.16.0+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Collecting huggingface-hub (from timm)\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors (from timm)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.66.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.23.5)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Installing collected packages: safetensors, huggingface-hub, timm\n",
            "Successfully installed huggingface-hub-0.18.0 safetensors-0.4.0 timm-0.9.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 665
        },
        "id": "rX4yTP_QKJNf",
        "outputId": "0bbbe3ff-aed3-4edf-f9f7-41b08615a301"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: huggingface-hub, tokenizers, transformers\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.18.0\n",
            "    Uninstalling huggingface-hub-0.18.0:\n",
            "      Successfully uninstalled huggingface-hub-0.18.0\n",
            "Successfully installed huggingface-hub-0.17.3 tokenizers-0.14.1 transformers-4.34.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "huggingface_hub"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import timm\n",
        "from transformers import DistilBertModel , DistilBertConfig\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "l_kEA74qZnaj"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Configure():\n",
        "\n",
        "  #for caption tokenizer\n",
        "  max_length = 200\n",
        "\n",
        "\n",
        "  #for text and image encoder\n",
        "  image_model = 'resnet50'\n",
        "  image_embedding = 2048\n",
        "  text_model = 'distilbert-base-uncased'\n",
        "  text_embedding = 768\n",
        "  text_tokenizer = 'distilbert-base-uncased'\n",
        "\n",
        "  pretrained = True\n",
        "  trainable = True\n",
        "\n",
        "  #For projection head\n",
        "  projection_dim = 256\n",
        "  dropout = 0.1\n",
        "  num_projection_layers = 1\n",
        "\n",
        "\n",
        "  #For CLIP model\n",
        "  temperature = 1.0\n",
        "\n"
      ],
      "metadata": {
        "id": "j_csgcOgaq52"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#image_filenames and captions must have same length so if there are multiple captions of same image image_filename must be same for all.\n",
        "\n",
        "\n",
        "class CLIPdata(torch.utils.data.Dataset):\n",
        "  def __init__(self,image_filenames,captions,tokenizer,transform):\n",
        "    self.image_filenames = image_filenames\n",
        "    self.captions = list(captions)\n",
        "    self.encoded_options = tokenizer(list(captions),padding=True.truncation=True,max_length = Configure.max_length)\n",
        "    self.transform = transform\n",
        "\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    item = {\n",
        "        key: torch.tensor(values[idx])\n",
        "        for key, values in self.encoded_options.items() }\n",
        "\n",
        "        image = cv2.imread(f\"{Configure.image_path}/{self.image_filenames[idx]}\")\n",
        "        image = cv2.cvtColor(image,COLOR_BGR2RGB)\n",
        "        image = self.transform(image=image)['image']\n",
        "\n",
        "        item['image'] = torch.tensor(image).permute(2,0,1).float()\n",
        "        item['caption'] = self.captions[idx]\n",
        "\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.captions)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LmgK2rlwyEV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build Image Encoder\n",
        "class ImageEncoder(nn.Module):\n",
        "\n",
        "  def __init__(self,image_model=Configure.image_model,pretrained = Configure.pretrained,trainable = Configure.trainable):\n",
        "    self.model = timm.create_model(image_model,pretrained,global_pool='avg')\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.model(x)\n"
      ],
      "metadata": {
        "id": "oDSK-9PGdmYF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build Text Encoder\n",
        "\n",
        "class TextEncoder(nn.Module):\n",
        "\n",
        "  def __init__(self,text_model = Configure.text_model,pretrained = Configure.pretrained):\n",
        "\n",
        "    self.model = DistilBertModel.from_pretrained(text_model)\n",
        "    self.target_token_idx = 0\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self,input_ids,attention_mask):\n",
        "    output = self.model(input_ids = input_ids,attention_mask=attention_mask)\n",
        "    last_hidden_state = output.last_hidden_state\n",
        "    return last_hidden_state[:,self.target_token_idx,:]\n"
      ],
      "metadata": {
        "id": "TC-uwO-2nXa3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Bring both embeddings into same dimensions(Image and text)\n",
        "\n",
        "class ProjectHead(nn.Module):\n",
        "\n",
        "  def __init__(self,embedding_dim,projection_dim=Configure.projection_dim,dropout = Configure.dropout):\n",
        "          self.projection = nn.Linear(embedding_dim,projection_dim) #embedding_dim is size of i/p vector(2048 for images and 768 for text) and projection_dim is o/p vector of size 256\n",
        "          self.gelu = nn.GELU()\n",
        "          self.fc = nn.Linear(projection_dim,projection_dim)\n",
        "          self.dropout = nn.Dropout(dropout)\n",
        "          self.layer_norm = nn.LayerNorm(projection_dim)\n",
        "\n",
        "  def forward(self,x):\n",
        "        projected = self.projection(x)\n",
        "        x = self.gelu(projected)\n",
        "        x = self.fc(x)\n",
        "        x = self.dropout(x)\n",
        "        x = x + projected\n",
        "        x = self.layer_norm(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "PdgIw-B0ZsLz"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CLIPModel(nn.Module):\n",
        "\n",
        "  def __init__(self,temperature=Configure.temperature,image_embedding = Configure.image_embedding,text_embedding = Configure.text_embedding):\n",
        "    self.image_encoder = ImageEncoder()\n",
        "    self.text_encoder = TextEncoder()\n",
        "    self.image_projection = ProjectHead(embedding_dim=image_embedding)\n",
        "    self.text_projection = ProjectHead(embedding_dim = text_embedding)\n",
        "    self.temperature = temperature\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def forward():\n",
        "    #Get image and text features\n",
        "    image_features = self.image_encoder(batch['image'])\n",
        "    text_features =  self.text_encoder(input_ids = batch['input_ids'],attention_mask = batch['attention_mask'])\n",
        "\n",
        "    #Get image and text embeedings(with same dim)\n",
        "    image_embeddings = self.image_projection(image_features)\n",
        "    text_embeddings = self.text_projection(text_features)\n",
        "\n",
        "\n",
        "    #calculate loss\n",
        "    logits = (text_embeddings @ image_embeddings.T) / self.temperature\n",
        "    image_similarity = image_embeddings @ image_embeddings.T\n",
        "    text_similarity = text_similarity @text_similarity.T\n",
        "\n",
        "    target = F.softmax((image_similarity + text_similarity)/2 * self.temperature,dim= -1)\n",
        "\n",
        "    text_loss = cross_entropy(logits,target,reduction = 'None')\n",
        "    image_loss = cross_entropy(logits.T,target.T,reduction = 'None')\n",
        "    loss = image_loss + text_loss\n",
        "\n",
        "    return loss.mean()\n",
        "\n",
        "\n",
        "\n",
        "    def cross_entropy(preds,target,reduction='None'):\n",
        "        log_softmax = nn.LogSoftMax(dim = -1)\n",
        "        loss = -targets * log_softmax(preds).sum(1)\n",
        "        if reduction == \"None\":\n",
        "            return loss\n",
        "        elif reduction == 'mean':\n",
        "            return loss.mean()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Rmep_UunjoUV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n82-L2Z5uBSU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}